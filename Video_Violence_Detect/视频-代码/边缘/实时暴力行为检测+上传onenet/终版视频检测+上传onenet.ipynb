{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e28bc06",
   "metadata": {},
   "source": [
    "### onenet上传声音事件类型\n",
    "准备条件：\n",
    " pip install paho-mqtt \n",
    "\n",
    "参数修改： \n",
    "client_id: 设备ID。  \n",
    "username: 产品的ID，用于标识OneNet平台上的产品。  \n",
    "accesskey: 设备的访问密钥，用于生成认证Token。  \n",
    "event_data: 要发布到OneNet平台的数据  \n",
    "等待时间：time.sleep(1)单位为s，可修改  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73bd37",
   "metadata": {},
   "source": [
    "##仅onenet上传模拟数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e64132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hq134\\AppData\\Local\\Temp\\ipykernel_29276\\1779066622.py:49: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  client = mqtt.Client(client_id=client_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated token: version=2018-10-31&res=products%2FZBPW56xh7m%2Fdevices%2Fcamera&et=1782946230&method=sha256&sign=5Y%2BRftEDAUfhr5BFKfvXR%2Fp7eNrHP1dk8AQ%2BjG1qBFc%3D\n",
      "Connected successfully.\n",
      "Published to $sys/ZBPW56xh7m/camera/thing/event/post: {'id': '123', 'version': '1.0', 'params': {'camera_violence': {'value': {'time_violence': 1746946231699, 'confidence_violence': 0.4}, 'time': 1746946231699}}}\n",
      "Received message '{\"id\":\"123\",\"code\":200,\"msg\":\"success\"}' on topic '$sys/ZBPW56xh7m/camera/thing/event/post/reply'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MQTTErrorCode.MQTT_ERR_SUCCESS: 0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import base64\n",
    "import hmac\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "\n",
    "# MQTT Broker 配置\n",
    "broker = \"studio-mqtt.heclouds.com\"\n",
    "port = 1883\n",
    "\n",
    "client_id = \"camera\"  # 从您的配置中获取\n",
    "username = \"ZBPW56xh7m\"  # 从您的配置中获取\n",
    "accesskey = \"H1H/FdM3vRfraZNhsSed0We90/OjwX91E6OX529vdac=\"  # 请替换为您的实际访问密钥,产品密钥，需短信验证\n",
    "\n",
    "# 认证token生成函数\n",
    "def get_token(product_id, device_name, access_key):\n",
    "    version = '2018-10-31'\n",
    "    res = \"products/\" + product_id + \"/devices/\" + device_name\n",
    "    et = str(int(time.time()) + 36000000)\n",
    "    method = 'sha256'\n",
    "    key = base64.b64decode(access_key)\n",
    "\n",
    "    org = et + '\\n' + method + '\\n' + res + '\\n' + version\n",
    "    sign_b = hmac.new(key=key, msg=org.encode(), digestmod=method)\n",
    "    sign = base64.b64encode(sign_b.digest()).decode()\n",
    "\n",
    "    sign = quote(sign, safe='')\n",
    "    res = quote(res, safe='')\n",
    "\n",
    "    token = 'version=%s&res=%s&et=%s&method=%s&sign=%s' % (version, res, et, method, sign)\n",
    "\n",
    "    return token\n",
    "\n",
    "# 当客户端收到来自服务器的CONNACK响应时的回调\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    if rc == 0:\n",
    "        print(\"Connected successfully.\")\n",
    "        # 连接成功后就订阅topic\n",
    "        client.subscribe(\"$sys/\" + username + \"/\" + client_id + \"/thing/event/post/reply\", qos=1)\n",
    "    else:\n",
    "        print(\"Failed to connect, return code \" + str(rc))\n",
    "\n",
    "# 从服务器接收发布消息时的回调。\n",
    "def on_message(client, userdata, message):\n",
    "    print(f\"Received message '{message.payload.decode()}' on topic '{message.topic}'\")\n",
    "\n",
    "# 创建 MQTT 客户端实例\n",
    "client = mqtt.Client(client_id=client_id)\n",
    "client.on_connect = on_connect\n",
    "client.on_message = on_message\n",
    "\n",
    "# 生成认证 Token\n",
    "password = get_token(username, client_id, accesskey)\n",
    "print(\"Generated token:\", password)\n",
    "\n",
    "# 连接到 MQTT 服务器\n",
    "client.username_pw_set(username, password)\n",
    "client.connect(broker, port, 60)\n",
    "\n",
    "# 启动网络循环以处理连接\n",
    "client.loop_start()\n",
    "\n",
    "# 等待一段时间以完成连接测试\n",
    "time.sleep(1)\n",
    "\n",
    "# 构建暴力行为检测事件数据\n",
    "start_time = int(time.time() * 1000)  # 时间戳（毫秒级）\n",
    "confidence_value = 0.4  # 可信度（示例值）\n",
    "\n",
    "event_data = {\n",
    "    \"id\": \"123\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"params\": {\n",
    "        \"camera_violence\": {  # 对应图中标识符\n",
    "            \"value\": {\n",
    "                \"time_violence\": start_time,  # 暴力行为检测时间\n",
    "                \"confidence_violence\": confidence_value  # 可信度\n",
    "            },\n",
    "            \"time\": start_time  # 事件时间\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 发布事件数据\n",
    "topic = \"$sys/\" + username + \"/\" + client_id + \"/thing/event/post\"\n",
    "client.publish(topic, json.dumps(event_data))\n",
    "print(f\"Published to {topic}: {event_data}\")\n",
    "\n",
    "# 等待一段时间以接收回复\n",
    "time.sleep(1)\n",
    "\n",
    "# 停止网络循环并断开连接\n",
    "client.loop_stop()\n",
    "client.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f7a00b",
   "metadata": {},
   "source": [
    "## 仅仅实时视频检测暴力行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590ce4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 模型加载成功: D:/jnu/物联网设计/视频处理/Real-Time-Violence-Detection-main/bestt.keras\n",
      "[INFO] 已连接到 RTSP 流，按 'q' 退出\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31s/step\n",
      "[WARNING] 读取帧失败，正在重新连接...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "[INFO] 程序已退出\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "# ======================\n",
    "# 配置与常量定义\n",
    "# ======================\n",
    "os.environ['FFMPEG_LOGLEVEL'] = 'verbose'  # 启用 FFmpeg 详细日志（显示解码错误）\n",
    "\n",
    "# 模型与视频参数\n",
    "IMG_SIZE = 128                # 输入模型的图像尺寸\n",
    "FRAME_COUNT = 15              # 积累帧数用于时间序列预测\n",
    "CLASS_NAMES = ['No Violence', 'Violence']  # 分类标签\n",
    "CONFIDENCE_THRESHOLD = 0.5    # 置信度阈值\n",
    "QUEUE_SIZE = 10               # 滑动平均队列大小\n",
    "RTSP_URL = 'http://192.168.137.231/mjpeg/1'    # 请替换为你的 RTSP 流地址\n",
    "#rtmp://47.94.236.247/live/stream\n",
    "MODEL_PATH ='D:/jnu/物联网设计/视频处理/Real-Time-Violence-Detection-main/bestt.keras'    # 模型路径\n",
    "\n",
    "# ======================\n",
    "# 模型加载\n",
    "# ======================\n",
    "try:\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(f\"[INFO] 模型加载成功: {MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] 模型加载失败: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "# ======================\n",
    "# 帧预处理函数\n",
    "# ======================\n",
    "def preprocess_frame(frame, size=(IMG_SIZE, IMG_SIZE)):\n",
    "    \"\"\"预处理帧：缩放、BGR转RGB、归一化\"\"\"\n",
    "    frame = cv2.resize(frame, size)\n",
    "    frame = frame[:, :, [2, 1, 0]]  # OpenCV BGR转RGB\n",
    "    frame = frame / 255.0  # 归一化到 [0, 1]\n",
    "    return frame\n",
    "\n",
    "# ======================\n",
    "# 预测后处理函数\n",
    "# ======================\n",
    "def smooth_predictions(prediction, queue):\n",
    "    \"\"\"滑动平均平滑预测结果\"\"\"\n",
    "    queue.append(prediction)\n",
    "    return np.mean(queue)\n",
    "\n",
    "def majority_voting(queue, threshold=CONFIDENCE_THRESHOLD):\n",
    "    \"\"\"多数投票：超过阈值的预测占比是否过半\"\"\"\n",
    "    count = sum(1 for p in queue if p > threshold)\n",
    "    return count / len(queue) > threshold\n",
    "\n",
    "# ======================\n",
    "# 主函数：实时视频流处理\n",
    "# ======================\n",
    "def classify_live_stream():\n",
    "    cap = cv2.VideoCapture(RTSP_URL)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"[ERROR] 无法打开 RTSP 流: {RTSP_URL}\")\n",
    "        print(\"[提示] 请检查 RTSP 地址是否正确，设备是否在线\")\n",
    "        exit(1)\n",
    "\n",
    "    print(f\"[INFO] 已连接到 RTSP 流，按 'q' 退出\")\n",
    "    frames = []                  # 待预测的帧序列\n",
    "    prediction_queue = deque(maxlen=QUEUE_SIZE)  # 预测结果队列\n",
    "\n",
    "    while True:\n",
    "        # 1. 读取视频帧\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # 2. 处理帧读取失败（RTSP 流常见问题）\n",
    "        if not ret:\n",
    "            print(\"[WARNING] 读取帧失败，正在重新连接...\")\n",
    "            \n",
    "            # 释放资源并重新连接\n",
    "            cap.release()\n",
    "            cap = cv2.VideoCapture(RTSP_URL)\n",
    "            if not cap.isOpened():\n",
    "                print(\"[ERROR] 重新连接失败，继续重试...\")\n",
    "                continue\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            display_frame = cv2.resize(frame, (800, 600))  # 调整显示窗口大小\n",
    "            processed_frame = preprocess_frame(frame)\n",
    "            frames.append(processed_frame)\n",
    "\n",
    "            is_violent = False          # 初始化默认状态：安全\n",
    "            display_text = \"No Violence\"  # 默认显示文本\n",
    "            \n",
    "            # 3. 积累足够帧后进行预测\n",
    "            if len(frames) == FRAME_COUNT:\n",
    "                input_array = np.expand_dims(np.array(frames), axis=0)\n",
    "                prediction = model.predict(input_array)[0][0]  # 获取预测概率（0-1）\n",
    "                smoothed_pred = smooth_predictions(prediction, prediction_queue)\n",
    "                \n",
    "                # 基础判断：超过置信度阈值\n",
    "                is_violent = smoothed_pred > CONFIDENCE_THRESHOLD\n",
    "                # 多数投票（队列满时启用，减少抖动）\n",
    "                if len(prediction_queue) == QUEUE_SIZE:\n",
    "                    is_violent = majority_voting(prediction_queue)\n",
    "                \n",
    "                # 生成带置信度的标签\n",
    "                confidence = f\"{smoothed_pred:.2f}\"\n",
    "                display_text = (\n",
    "                    f\"Violence (Confidence: {confidence})\" \n",
    "                    if is_violent \n",
    "                    else \"No Violence\"\n",
    "                )\n",
    "\n",
    "                frames = []  # 清空帧列表，等待下一周期\n",
    "\n",
    "            # 4. 在视频帧上绘制标签（颜色区分状态：绿色=安全，红色=暴力）\n",
    "            color = (0, 255, 0) if not is_violent else (0, 0, 255)\n",
    "            cv2.putText(\n",
    "                display_frame,\n",
    "                display_text,\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                color,\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "            # 5. 显示视频帧\n",
    "            cv2.imshow('Real-Time Violence Detection', display_frame)\n",
    "\n",
    "        except Exception as e:\n",
    "            # 捕获 Python 异常（如模型输入错误、数组操作错误）\n",
    "            print(f\"[ERROR] 帧处理失败: {str(e)}\")\n",
    "            if frame is not None:\n",
    "                print(f\"[DEBUG] 帧尺寸: {frame.shape}, 数据类型: {frame.dtype}\")\n",
    "            continue  # 跳过当前错误帧，继续处理下一帧\n",
    "\n",
    "        # 6. 退出逻辑（按 'q' 键）\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # 释放资源\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[INFO] 程序已退出\")\n",
    "\n",
    "# ======================\n",
    "# 程序入口\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    classify_live_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfba98",
   "metadata": {},
   "source": [
    "## 实时检测+上传onenet：\n",
    "由于onenet代码里设置了1s的等待回复，且不想一直与onenet保持连接，所以设置多线程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a58381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import base64\n",
    "import hmac\n",
    "import time\n",
    "from urllib.parse import quote\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import threading\n",
    "\n",
    "# ======================\n",
    "# 配置与常量定义\n",
    "# ======================\n",
    "os.environ['FFMPEG_LOGLEVEL'] = 'verbose'\n",
    "IMG_SIZE = 128\n",
    "FRAME_COUNT = 15\n",
    "CLASS_NAMES = ['No Violence', 'Violence']\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "QUEUE_SIZE = 10\n",
    "RTSP_URL = 'http://192.168.137.165/mjpeg/1'\n",
    "MODEL_PATH = 'D:/jnu/物联网设计/视频处理/Real-Time-Violence-Detection-main/bestt.keras'\n",
    "\n",
    "# ======================\n",
    "# OneNET 配置\n",
    "# ======================\n",
    "broker = \"studio-mqtt.heclouds.com\"\n",
    "port = 1883\n",
    "client_id = \"camera\"\n",
    "username = \"ZBPW56xh7m\"\n",
    "accesskey = \"H1H/FdM3vRfraZNhsSed0We90/OjwX91E6OX529vdac=\"\n",
    "\n",
    "# ======================\n",
    "# OneNET 核心函数\n",
    "# ======================\n",
    "def get_token(product_id, device_name, access_key):\n",
    "    version = '2018-10-31'\n",
    "    res = f\"products/{product_id}/devices/{device_name}\"\n",
    "    et = str(int(time.time()) + 36000000)\n",
    "    method = 'sha256'\n",
    "    key = base64.b64decode(access_key)\n",
    "    org = f\"{et}\\n{method}\\n{res}\\n{version}\"\n",
    "    sign_b = hmac.new(key=key, msg=org.encode(), digestmod=method)\n",
    "    sign = base64.b64encode(sign_b.digest()).decode()\n",
    "    sign = quote(sign, safe='')\n",
    "    res = quote(res, safe='')\n",
    "    return f'version={version}&res={res}&et={et}&method={method}&sign={sign}'\n",
    "\n",
    "def upload_violence_to_onenet(confidence):\n",
    "    client = mqtt.Client(client_id=client_id)\n",
    "    \n",
    "    def on_connect(client, userdata, flags, rc):\n",
    "        if rc == 0:\n",
    "            print(\"Connected successfully.\")\n",
    "            client.subscribe(f\"$sys/{username}/{client_id}/thing/event/post/reply\", qos=1)\n",
    "        else:\n",
    "            print(f\"Failed to connect, return code {rc}\")\n",
    "    \n",
    "    def on_message(client, userdata, message):\n",
    "        print(f\"Received message: {message.payload.decode()}\")\n",
    "    \n",
    "    client.on_connect = on_connect\n",
    "    client.on_message = on_message\n",
    "    password = get_token(username, client_id, accesskey)\n",
    "    client.username_pw_set(username, password)\n",
    "    client.connect(broker, port, 60)\n",
    "    client.loop_start()\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    event_data = {\n",
    "        \"id\": \"123\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"params\": {\n",
    "            \"camera_violence\": {\n",
    "                \"value\": {\n",
    "                    \"time_violence\": int(time.time() * 1000),\n",
    "                    \"confidence_violence\": round(float(confidence), 2)\n",
    "                },\n",
    "                \"time\": int(time.time() * 1000)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    client.publish(f\"$sys/{username}/{client_id}/thing/event/post\", json.dumps(event_data))\n",
    "    print(f\"Uploaded: {event_data}\")\n",
    "    time.sleep(1)\n",
    "    client.loop_stop()\n",
    "    client.disconnect()\n",
    "\n",
    "# ======================\n",
    "# 视频检测核心函数（含平滑处理）\n",
    "# ======================\n",
    "def preprocess_frame(frame):\n",
    "    frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "    frame = frame[:, :, [2, 1, 0]]  # BGR转RGB\n",
    "    frame = frame / 255.0  # 归一化\n",
    "    return frame\n",
    "\n",
    "def smooth_predictions(prediction, queue):\n",
    "    queue.append(prediction)\n",
    "    return np.mean(queue)\n",
    "\n",
    "def majority_voting(queue, threshold=CONFIDENCE_THRESHOLD):\n",
    "    count = sum(1 for p in queue if p > threshold)\n",
    "    return count / len(queue) > threshold\n",
    "\n",
    "def classify_live_stream():\n",
    "    model = load_model(MODEL_PATH)\n",
    "    cap = cv2.VideoCapture(RTSP_URL)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open RTSP stream {RTSP_URL}\")\n",
    "        return\n",
    "    \n",
    "    frames = []\n",
    "    prediction_queue = deque(maxlen=QUEUE_SIZE)\n",
    "    last_upload_time = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Warning: Failed to read frame, reconnecting...\")\n",
    "            cap.release()\n",
    "            cap = cv2.VideoCapture(RTSP_URL)\n",
    "            continue\n",
    "        \n",
    "        display_frame = cv2.resize(frame, (800, 600))\n",
    "        processed_frame = preprocess_frame(frame)\n",
    "        frames.append(processed_frame)\n",
    "        \n",
    "        is_violent = False\n",
    "        display_text = \"No Violence\"  # 默认不显示置信度\n",
    "        \n",
    "        # 仅在积累足够帧时进行预测\n",
    "        if len(frames) == FRAME_COUNT:\n",
    "            input_array = np.expand_dims(np.array(frames), axis=0)\n",
    "            prediction = model.predict(input_array)[0][0]\n",
    "            smoothed_pred = smooth_predictions(prediction, prediction_queue)  # 滑动平均\n",
    "            is_violent = smoothed_pred > CONFIDENCE_THRESHOLD\n",
    "            \n",
    "            # 多数投票（队列满时启用）\n",
    "            if len(prediction_queue) == QUEUE_SIZE:\n",
    "                is_violent = majority_voting(prediction_queue)\n",
    "            \n",
    "            confidence = f\"{smoothed_pred:.2f}\"\n",
    "            display_text = (\n",
    "                f\"Violence (Confidence: {confidence})\" \n",
    "                if is_violent \n",
    "                else \"No Violence\"\n",
    "            )\n",
    "            frames = []  # 清空帧队列\n",
    "            \n",
    "            # 上传逻辑（示例：可添加间隔控制）\n",
    "            if is_violent and (time.time() - last_upload_time) >= 5:\n",
    "                threading.Thread(target=upload_violence_to_onenet, args=(smoothed_pred,)).start()\n",
    "                last_upload_time = time.time()\n",
    "        \n",
    "        # 绘制文本（确保smoothed_pred仅在预测时存在）\n",
    "        color = (0, 255, 0) if not is_violent else (0, 0, 255)\n",
    "        cv2.putText(\n",
    "            display_frame,\n",
    "            display_text,\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.8,\n",
    "            color,\n",
    "            2,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "        \n",
    "        cv2.imshow('Real-Time Violence Detection', display_frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ======================\n",
    "# 程序入口\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    classify_live_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
